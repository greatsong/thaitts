import streamlit as st
from pathlib import Path
import openai

# OpenAI API í‚¤ ì„¤ì •
openai.api_key = st.secrets["openai_api_key"]

# Streamlit UI êµ¬ì„±
st.title("ğŸŒŸ í•˜ëŠ˜ì”¨ì•—êµíšŒ íƒœêµ­ ì„ êµ íŒŒì´íŒ…!! ğŸŒŸ")
st.subheader("ğŸ‡¹ğŸ‡­ í•œê¸€ ë˜ëŠ” íƒœêµ­ì–´ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”!")

st.write("ğŸ§ **í…ìŠ¤íŠ¸ë¥¼ ë²ˆì—­í•˜ê³  ë°œìŒì„ í™•ì¸í•˜ë©° ìŒì„±ì„ ìƒì„±í•©ë‹ˆë‹¤.** ğŸ§")

# ì…ë ¥ ì–¸ì–´ ì„ íƒ
input_language = st.radio(
    "ì…ë ¥ ì–¸ì–´ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
    ["í•œê¸€", "íƒœêµ­ì–´"],
    index=0  # ê¸°ë³¸ê°’: í•œê¸€
)

# ì…ë ¥ ë°©ì‹ ì„ íƒ
input_method = st.radio(
    "ì…ë ¥ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:",
    ["í…ìŠ¤íŠ¸ ì°½ ì…ë ¥", "í…ìŠ¤íŠ¸ íŒŒì¼ ì—…ë¡œë“œ"],
    index=0  # ê¸°ë³¸ê°’: í…ìŠ¤íŠ¸ ì°½ ì…ë ¥
)

# í…ìŠ¤íŠ¸ ì…ë ¥ ë˜ëŠ” íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
if input_method == "í…ìŠ¤íŠ¸ ì°½ ì…ë ¥":
    user_text = st.text_area("ğŸ“ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
elif input_method == "í…ìŠ¤íŠ¸ íŒŒì¼ ì—…ë¡œë“œ":
    uploaded_file = st.file_uploader("ğŸ“‚ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”:", type=["txt"])
    if uploaded_file is not None:
        user_text = uploaded_file.read().decode("utf-8")
    else:
        user_text = ""

# ChatGPTë¥¼ ì´ìš©í•œ ë²ˆì—­ ë° ë°œìŒ ìƒì„± í•¨ìˆ˜
def translate_and_transliterate(text, source_lang):
    if source_lang == "í•œê¸€":
        prompt = f"Translate the following Korean text into Thai and provide its pronunciation in Korean script:\n{text}"
    else:
        prompt = f"Translate the following Thai text into Korean and provide its pronunciation in Thai script:\n{text}"

    response = openai.ChatCompletion.create(
        model="gpt-4",  # ê¸°ë³¸ ëª¨ë¸: gpt-4
        messages=[
            {"role": "system", "content": "You are a translation assistant."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3,
    )
    output = response.choices[0].message["content"]
    lines = output.split("\n")
    translation = lines[0].strip()
    pronunciation = lines[1].strip() if len(lines) > 1 else "Pronunciation not available"
    return translation, pronunciation

# TTS ìƒì„± í•¨ìˆ˜
def generate_tts(text, voice="shimmer"):
    output_mp3_path = Path("output.mp3")
    response = openai.Audio.create(
        model="tts-1",
        voice=voice,
        input=text,
    )
    with open(output_mp3_path, "wb") as f:
        f.write(response.content)
    return output_mp3_path

# ë³€í™˜ ë° MP3 ìƒì„± ì²˜ë¦¬
if st.button("ë²ˆì—­ ë° MP3 ìƒì„±"):
    if not user_text.strip():
        st.error("âŒ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    else:
        # ë²ˆì—­ ë° ë°œìŒ ìƒì„±
        st.write("ğŸ”„ ë²ˆì—­ ì¤‘...")
        translation, pronunciation = translate_and_transliterate(user_text, input_language)

        st.write("ğŸŒ ë²ˆì—­ ê²°ê³¼:")
        st.markdown(f"**ì…ë ¥ ({input_language}):** {user_text}")
        st.markdown(f"**ë²ˆì—­ ê²°ê³¼:** {translation}")
        st.markdown(f"**ë°œìŒ:** {pronunciation}")

        # TTS ìƒì„±
        st.write("ğŸ§ MP3 ìƒì„± ì¤‘...")
        mp3_path = generate_tts(translation)

        # MP3 íŒŒì¼ ì œê³µ
        with open(mp3_path, "rb") as mp3_file:
            st.audio(mp3_file.read(), format="audio/mp3")
            st.download_button(
                label="ğŸ“¥ MP3 íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=mp3_file,
                file_name="output.mp3",
                mime="audio/mp3",
            )

        st.success("âœ… ë²ˆì—­ ë° MP3 ìƒì„± ì™„ë£Œ! ğŸ‰")
